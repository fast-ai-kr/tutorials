{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look inside DataBlock \n",
    "> Let's dig into DataBlock source code. By doing this, we could define our custom DataBlock class that fits to our problems.\n",
    "- author: \"Chansung Park\"\n",
    "- toc: true\n",
    "- comments: true\n",
    "- categories: [data, fastai]\n",
    "- permalink: /data_block/\n",
    "- badges: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=parent_label,\n",
    "                   item_tfms=Resize(224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from /home/ubuntu/.fastai/data/oxford-iiit-pet\n",
      "Found 14780 items\n",
      "2 datasets of sizes 11824,2956\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: PILBase.create\n",
      "    starting from\n",
      "      /home/ubuntu/.fastai/data/oxford-iiit-pet/images/japanese_chin_188.jpg\n",
      "    applying PILBase.create gives\n",
      "      PILImage mode=RGB size=500x375\n",
      "  Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "    starting from\n",
      "      /home/ubuntu/.fastai/data/oxford-iiit-pet/images/japanese_chin_188.jpg\n",
      "    applying parent_label gives\n",
      "      images\n",
      "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
      "      TensorCategory(0)\n",
      "\n",
      "Final sample: (PILImage mode=RGB size=500x375, TensorCategory(0))\n",
      "\n",
      "\n",
      "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "    starting from\n",
      "      (PILImage mode=RGB size=500x375, TensorCategory(0))\n",
      "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
      "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
      "    applying ToTensor gives\n",
      "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "    starting from\n",
      "      (TensorImage of size 4x3x224x224, TensorCategory([0, 1, 0, 1], device='cuda:0'))\n",
      "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
      "      (TensorImage of size 4x3x224x224, TensorCategory([0, 1, 0, 1], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "dblock.summary(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ImageBlock](https://github.com/fastai/fastai/blob/master/fastai/vision/data.py#L57)\n",
    "\n",
    "```python\n",
    "def ImageBlock(cls=PILImage):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=IntToFloatTensor)\n",
    "\n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "        self.type_tfms  =            L(type_tfms)\n",
    "        self.item_tfms  = ToTensor + L(item_tfms)\n",
    "        self.batch_tfms =            L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\n",
    "        \n",
    "class PILBase(Image.Image, metaclass=BypassNewMeta):\n",
    "    _bypass_type=Image.Image\n",
    "    _show_args = {'cmap':'viridis'}\n",
    "    _open_args = {'mode': 'RGB'}\n",
    "    @classmethod\n",
    "    def create(cls, fn:(Path,str,Tensor,ndarray,bytes), **kwargs)->None:\n",
    "        \"Open an `Image` from path `fn`\"\n",
    "        if isinstance(fn,TensorImage): fn = fn.permute(1,2,0).type(torch.uint8)\n",
    "        if isinstance(fn, TensorMask): fn = fn.type(torch.uint8)\n",
    "        if isinstance(fn,Tensor): fn = fn.numpy()\n",
    "        if isinstance(fn,ndarray): return cls(Image.fromarray(fn))\n",
    "        if isinstance(fn,bytes): fn = io.BytesIO(fn)\n",
    "        return cls(load_image(fn, **merge(cls._open_args, kwargs)))\n",
    "\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        \"Show image using `merge(self._show_args, kwargs)`\"\n",
    "        return show_image(self, ctx=ctx, **merge(self._show_args, kwargs))\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__} mode={self.mode} size={\"x\".join([str(d) for d in self.size])}'\n",
    "\n",
    "class PILImage(PILBase): pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CategoryBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/data/block.py#L22)\n",
    "\n",
    "```python\n",
    "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
    "    \"`TransformBlock` for single-label categorical targets\"\n",
    "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))\n",
    "\n",
    "class Categorize(DisplayedTransform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func, order=CrossEntropyLossFlat(), 1\n",
    "    \n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        if vocab is not None: vocab = CategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: \n",
    "            self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na)\n",
    "            \n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o):\n",
    "        try:\n",
    "            return TensorCategory(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])\n",
    "    \n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False, strict=False):\n",
    "        if is_categorical_dtype(col):\n",
    "            items = L(col.cat.categories, use_list=True)\n",
    "            #Remove non-used categories while keeping order\n",
    "            if strict: items = L(o for o in items if o in col.unique())\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "\n",
    "    def map_objs(self,objs):\n",
    "        \"Map `objs` to IDs\"\n",
    "        return L(self.o2i[o] for o in objs)\n",
    "\n",
    "    def map_ids(self,ids):\n",
    "        \"Map `ids` to objects in vocab\"\n",
    "        return L(self.items[o] for o in ids)\n",
    "\n",
    "    def __eq__(self,b): return all_equal(b,self)    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Block (Official)\n",
    "\n",
    "General \n",
    "- CategoryBlock\n",
    "- MultiCategoryBlock\n",
    "- RegressionBlock\n",
    "\n",
    "Computer Vision\n",
    "- ImageBlock\n",
    "- MaskBlock\n",
    "- PointBlock\n",
    "- BBoxBlock\n",
    "- BBoxLblBlock\n",
    "\n",
    "NLP\n",
    "- TextBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PointBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/vision/data.py#L67)\n",
    "\n",
    "```python\n",
    "PointBlock = TransformBlock(type_tfms=TensorPoint.create, item_tfms=PointScaler)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MaskBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/vision/data.py#L62)\n",
    "\n",
    "```python\n",
    "def MaskBlock(codes=None):\n",
    "    \"A `TransformBlock` for segmentation masks, potentially with `codes`\"\n",
    "    return TransformBlock(type_tfms=PILMask.create, item_tfms=AddMaskCodes(codes=codes), batch_tfms=IntToFloatTensor)\n",
    "\n",
    "class PILMask(PILBase): _open_args,_show_args = {'mode':'L'},{'alpha':0.5, 'cmap':'tab20'}\n",
    "\n",
    "class AddMaskCodes(Transform):\n",
    "    \"Add the code metadata to a `TensorMask`\"\n",
    "    def __init__(self, codes=None):\n",
    "        self.codes = codes\n",
    "        if codes is not None: self.vocab,self.c = codes,len(codes)\n",
    "\n",
    "    def decodes(self, o:TensorMask):\n",
    "        if self.codes is not None: o._meta = {'codes': self.codes}\n",
    "        return o\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BBoxBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/vision/data.py#L68)\n",
    "```python\n",
    "BBoxBlock = TransformBlock(type_tfms=TensorBBox.create, item_tfms=PointScaler, dls_kwargs = {'before_batch': bb_pad})\n",
    "\n",
    "class TensorBBox(TensorPoint):\n",
    "    \"Basic type for a tensor of bounding boxes in an image\"\n",
    "    @classmethod\n",
    "    def create(cls, x, img_size=None)->None: return cls(tensor(x).view(-1, 4).float(), img_size=img_size)\n",
    "\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        x = self.view(-1,4)\n",
    "        for b in x: _draw_rect(ctx, b, hw=False, **kwargs)\n",
    "        return ctx\n",
    "    \n",
    "class PointScaler(Transform):\n",
    "    \"Scale a tensor representing points\"\n",
    "    order = 1\n",
    "    def __init__(self, do_scale=True, y_first=False): self.do_scale,self.y_first = do_scale,y_first\n",
    "    def _grab_sz(self, x):\n",
    "        self.sz = [x.shape[-1], x.shape[-2]] if isinstance(x, Tensor) else x.size\n",
    "        return x\n",
    "\n",
    "    def _get_sz(self, x):\n",
    "        sz = x.get_meta('img_size')\n",
    "        assert sz is not None or self.sz is not None, \"Size could not be inferred, pass it in the init of your TensorPoint with `img_size=...`\"\n",
    "        return sz if self.sz is None else self.sz\n",
    "\n",
    "    def setups(self, dl):\n",
    "        its = dl.do_item(0)\n",
    "        for t in its:\n",
    "            if isinstance(t, TensorPoint): self.c = t.numel()\n",
    "\n",
    "    def encodes(self, x:(PILBase,TensorImageBase)): return self._grab_sz(x)\n",
    "    def decodes(self, x:(PILBase,TensorImageBase)): return self._grab_sz(x)\n",
    "\n",
    "    def encodes(self, x:TensorPoint): return _scale_pnts(x, self._get_sz(x), self.do_scale, self.y_first)\n",
    "    def decodes(self, x:TensorPoint): return _unscale_pnts(x.view(-1, 2), self._get_sz(x))    \n",
    "```\n",
    "\n",
    "## [BBoxLblBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/vision/data.py#L74)\n",
    "```python\n",
    "def BBoxLblBlock(vocab=None, add_na=True):\n",
    "    \"A `TransformBlock` for labeled bounding boxes, potentially with `vocab`\"\n",
    "    return TransformBlock(type_tfms=MultiCategorize(vocab=vocab, add_na=add_na), item_tfms=BBoxLabeler)\n",
    "\n",
    "class BBoxLabeler(Transform):\n",
    "    def setups(self, dl): self.vocab = dl.vocab\n",
    "\n",
    "    def decode (self, x, **kwargs):\n",
    "        self.bbox,self.lbls = None,None\n",
    "        return self._call('decodes', x, **kwargs)\n",
    "\n",
    "    def decodes(self, x:TensorMultiCategory):\n",
    "        self.lbls = [self.vocab[a] for a in x]\n",
    "        return x if self.bbox is None else LabeledBBox(self.bbox, self.lbls)\n",
    "\n",
    "    def decodes(self, x:TensorBBox):\n",
    "        self.bbox = x\n",
    "        return self.bbox if self.lbls is None else LabeledBBox(self.bbox, self.lbls)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MultiCategoryBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/data/block.py#L27)\n",
    "```python\n",
    "def MultiCategoryBlock(encoded=False, vocab=None, add_na=False):\n",
    "    \"`TransformBlock` for multi-label categorical targets\"\n",
    "    tfm = EncodedMultiCategorize(vocab=vocab) if encoded else [MultiCategorize(vocab=vocab, add_na=add_na), OneHotEncode]\n",
    "    return TransformBlock(type_tfms=tfm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TextBlock](https://github.com/fastai/fastai/blob/603f1c32a5e4b0f8ec47c7e3a1a8278a0b45a170/fastai/text/data.py#L191)\n",
    "\n",
    "```python\n",
    "class TextBlock(TransformBlock):\n",
    "    \"A `TransformBlock` for texts\"\n",
    "    @delegates(Numericalize.__init__)\n",
    "    def __init__(self, tok_tfm, vocab=None, is_lm=False, seq_len=72, backwards=False, **kwargs):\n",
    "        type_tfms = [tok_tfm, Numericalize(vocab, **kwargs)]\n",
    "        if backwards: type_tfms += [reverse_text]\n",
    "        return super().__init__(type_tfms=type_tfms,\n",
    "                                dl_type=LMDataLoader if is_lm else SortedDL,\n",
    "                                dls_kwargs={'seq_len': seq_len} if is_lm else {'before_batch': partial(pad_input_chunk, seq_len=seq_len)})\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(Tokenizer.from_df, keep=True)\n",
    "    def from_df(cls, text_cols, vocab=None, is_lm=False, seq_len=72, backwards=False, min_freq=3, max_vocab=60000, **kwargs):\n",
    "        \"Build a `TextBlock` from a dataframe using `text_cols`\"\n",
    "        return cls(Tokenizer.from_df(text_cols, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,\n",
    "                   backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(Tokenizer.from_folder, keep=True)\n",
    "    def from_folder(cls, path, vocab=None, is_lm=False, seq_len=72, backwards=False, min_freq=3, max_vocab=60000, **kwargs):\n",
    "        \"Build a `TextBlock` from a `path`\"\n",
    "        return cls(Tokenizer.from_folder(path, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,\n",
    "                   backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
