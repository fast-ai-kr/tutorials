{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 블록 만드는 법 (1)\n",
    "\n",
    "> fastai에서는 데이터를 정의하는 방법으로 DataBlock API를 제안합니다. 각 인자가 의미하는 내용과, 실제 Siamese 공식 튜토리얼에 이 내용이 어떻게 적용되는지를 살펴봅니다.\n",
    "- author: \"Chansung Park\"\n",
    "- toc: true\n",
    "- image: images/datablock/siamese-block.png\n",
    "- comments: true\n",
    "- categories: [datablock, siamese, fastai]\n",
    "- permalink: /datablock-siamese/\n",
    "- badges: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Downloading fastai-2.1.5-py3-none-any.whl (188 kB)\n",
      "\u001b[K     |████████████████████████████████| 188 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from fastai) (2.23.0)\n",
      "Collecting torch>=1.7.0\n",
      "  Downloading torch-1.7.0-cp38-none-macosx_10_9_x86_64.whl (108.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 108.1 MB 6.1 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting fastcore>=1.3.0\n",
      "  Downloading fastcore-1.3.6-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from fastai) (20.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 63 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/site-packages (from fastai) (5.3.1)\n",
      "Collecting spacy\n",
      "  Downloading spacy-2.3.2-cp38-cp38-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.8/site-packages (from fastai) (20.1.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from fastai) (1.5.2)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting torchvision>=0.8\n",
      "  Downloading torchvision-0.8.1-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-8.0.1-cp38-cp38-macosx_10_10_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.3-cp38-cp38-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 74 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from fastai) (1.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->fastai) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->fastai) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from torch>=1.7.0->fastai) (1.19.2)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->fastai) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/protobuf/3.13.0/libexec/lib/python3.8/site-packages (from packaging->fastai) (1.15.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.4-cp38-cp38-macosx_10_9_x86_64.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp38-cp38-macosx_10_9_x86_64.whl (3.7 MB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.8.0-py3-none-any.whl (23 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.4-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Downloading tqdm-4.52.0-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from spacy->fastai) (49.2.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.4-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.4-cp38-cp38-macosx_10_9_x86_64.whl (263 kB)\n",
      "\u001b[K     |████████████████████████████████| 263 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc==7.4.1\n",
      "  Downloading thinc-7.4.1-cp38-cp38-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->fastai) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 278 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/site-packages (from pandas->fastai) (2020.1)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=df893b75609090dbe51a1811bb93ea7735d80a336150e5aac1f284a860c7ffb9\n",
      "  Stored in directory: /Users/chansungpark/Library/Caches/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: future, dataclasses, torch, fastcore, joblib, threadpoolctl, scikit-learn, srsly, blis, wasabi, plac, catalogue, murmurhash, tqdm, cymem, preshed, thinc, spacy, fastprogress, pillow, torchvision, cycler, kiwisolver, matplotlib, fastai\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cycler-0.10.0 cymem-2.0.4 dataclasses-0.6 fastai-2.1.5 fastcore-1.3.6 fastprogress-1.0.0 future-0.18.2 joblib-0.17.0 kiwisolver-1.3.1 matplotlib-3.3.3 murmurhash-1.0.4 pillow-8.0.1 plac-1.1.3 preshed-3.0.4 scikit-learn-0.23.2 spacy-2.3.2 srsly-1.0.4 thinc-7.4.1 threadpoolctl-2.1.0 torch-1.7.0 torchvision-0.8.1 tqdm-4.52.0 wasabi-0.8.0\n",
      "Collecting nbdev\n",
      "  Downloading nbdev-1.1.5-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 976 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/site-packages (from nbdev) (5.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from nbdev) (20.4)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/site-packages (from nbdev) (5.3.4)\n",
      "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.8/site-packages (from nbdev) (5.0.7)\n",
      "Requirement already satisfied: fastcore>=1.3.1 in /usr/local/lib/python3.8/site-packages (from nbdev) (1.3.6)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/site-packages (from nbdev) (6.1.7)\n",
      "Collecting nbconvert<6\n",
      "  Using cached nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/site-packages (from nbdev) (20.1.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/protobuf/3.13.0/libexec/lib/python3.8/site-packages (from packaging->nbdev) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->nbdev) (2.4.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/site-packages (from ipykernel->nbdev) (6.0.4)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/site-packages (from ipykernel->nbdev) (5.0.4)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/site-packages (from ipykernel->nbdev) (7.18.1)\n",
      "Requirement already satisfied: appnope; platform_system == \"Darwin\" in /usr/local/lib/python3.8/site-packages (from ipykernel->nbdev) (0.1.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (3.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/site-packages (from jupyter-client->nbdev) (2.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/site-packages (from jupyter-client->nbdev) (19.0.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (1.4.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (3.2.1)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (0.4.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (2.11.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (0.3)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (2.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/site-packages (from nbconvert<6->nbdev) (0.8.4)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (49.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (3.0.7)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->nbdev) (0.17.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (20.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/site-packages (from bleach->nbconvert<6->nbdev) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert<6->nbdev) (1.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->nbdev) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->nbdev) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->nbdev) (0.7.1)\n",
      "Installing collected packages: nbconvert, nbdev\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.0.6\n",
      "    Uninstalling nbconvert-6.0.6:\n",
      "      Successfully uninstalled nbconvert-6.0.6\n",
      "Successfully installed nbconvert-5.6.1 nbdev-1.1.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install fastai\n",
    "!pip install nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# path = untar_data(URLs.PETS)\n",
    "files = \"\"\n",
    "\n",
    "def label_func(fname):\n",
    "    return re.match(r'^(.*)_\\d+.jpg$', fname.name).groups()[0]\n",
    "\n",
    "class ImageTuple(fastuple):\n",
    "    @classmethod\n",
    "    def create(cls, fns): return cls(tuple(PILImage.create(f) for f in fns))\n",
    "    \n",
    "    def show(self, ctx=None, **kwargs): \n",
    "        t1,t2 = self\n",
    "        if not isinstance(t1, Tensor) or not isinstance(t2, Tensor) or t1.shape != t2.shape: return ctx\n",
    "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
    "        return show_image(torch.cat([t1,line,t2], dim=2), ctx=ctx, **kwargs)\n",
    "\n",
    "def ImageTupleBlock():\n",
    "    return TransformBlock(type_tfms=ImageTuple.create, batch_tfms=IntToFloatTensor)\n",
    "\n",
    "# splits = RandomSplitter()(files)\n",
    "# splits_files = [files[splits[i]] for i in range(2)]\n",
    "# splits_sets = mapped(set, splits_files)\n",
    "\n",
    "def get_split(f):\n",
    "    for i,s in enumerate(splits_sets):\n",
    "        if f in s: return i\n",
    "    raise ValueError(f'File {f} is not presented in any split.')\n",
    "\n",
    "# splbl2files = [{l: [f for f in s if label_func(f) == l] for l in labels} for s in splits_sets]\n",
    "\n",
    "def splitter(items): \n",
    "    def get_split_files(i): \n",
    "        return [j for j,(f1,f2,same) in enumerate(items) if get_split(f1)==i]\n",
    "\n",
    "    return get_split_files(0),get_split_files(1)\n",
    "\n",
    "def draw_other(f):\n",
    "    same = random.random() < 0.5\n",
    "\n",
    "    cls = label_func(f)\n",
    "    split = get_split(f)\n",
    "\n",
    "    if not same: \n",
    "        cls = random.choice(L(l for l in labels if l != cls)) \n",
    "\n",
    "    return random.choice(splbl2files[split][cls]), same\n",
    "\n",
    "def get_tuples(files): \n",
    "    return [[f, *draw_other(f)] for f in files]\n",
    "\n",
    "def get_x(t): \n",
    "    return t[:2]\n",
    "\n",
    "def get_y(t): \n",
    "    return t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"DataBlock\" class=\"doc_header\"><code>class</code> <code>DataBlock</code><a href=\"https://github.com/fastai/fastai/tree/master/fastai/data/block.py#L58\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>DataBlock</code>(**`blocks`**=*`None`*, **`dl_type`**=*`None`*, **`getters`**=*`None`*, **`n_inp`**=*`None`*, **`item_tfms`**=*`None`*, **`batch_tfms`**=*`None`*, **`get_items`**=*`None`*, **`splitter`**=*`None`*, **`get_y`**=*`None`*, **`get_x`**=*`None`*)\n",
       "\n",
       "Generic container to quickly build `Datasets` and `DataLoaders`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbdev.show_doc(DataBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataBlock**은 모델이 학습하는 데이터를 준비시키는 핵심 API 입니다. 중요한 사실은 **DataBlock**은 일종의 **템플릿** 이라는 것입니다. 실제로 데이터가 **주입되었을 때**, **'이런 이런 식으로 동작한다'** 를 정의하는 것이죠.\n",
    "\n",
    "상기 **DataBlock** API의 원형을 말로 풀어서 설명하면 다음과 같습니다.\n",
    "\n",
    "- **dls = siamese.dataloaders(files)**\n",
    "  - 이 부분은 DataBlock을 만든 후 수행되는 코드입니다.\n",
    "  - 입력된 것은 1이 수용할 데이터 목록입니다.\n",
    "\n",
    "\n",
    "- **get_items**: 수용된 데이터를 논리적인 집합 목록으로 만듭니다.\n",
    "  - 이 함수는 무엇을 반환해도 상관이 없습니다. 단, 반환된 값으로 입력될 데이터와 레이블의 추출이 가능해야 합니다.\n",
    "  - 이 단계에서 다뤄지는 **데이터**란, 아무런 변환 처리가 적용되지 않은 **raw** 입니다.\n",
    "    - *예시 1) 이미지 파일 경로의 목록 (경로에서 입력으로 사용될 파일이름과, 상위폴더로 결정 가능한 레이블이 모두 포함되어 있다면 OK)*\n",
    "    - *예시 2) (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 튜플들의 목록*\n",
    "\n",
    "\n",
    "- **get_x**: 무엇을 입력으로 삼을지 결정합니다.\n",
    "  - **get_items**이 반환한 목록을 하나씩 접근해서 처리합니다.\n",
    "  - 이 단계에서도 다뤄지는 데이터는 raw 입니다.\n",
    "    - *예시 1) 이미지 파일 경로를 그대로 반환 (bypass)*\n",
    "    - *예시 2) (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 튜플에서 1과 2를 추출해서 반환*\n",
    "\n",
    "\n",
    "- **get_y**: 무엇을 레이블로 삼을지 결정합니다. \n",
    "  - **get_items**이 반환한 목록을 하나씩 접근해서 처리합니다.\n",
    "  - 이 단계에서도 다뤄지는 데이터는 raw 입니다.\n",
    "    - *예시 1) 이미지 파일 경로에서 상위 폴더명을 추출해서 반환*\n",
    "    - *예시 2) (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 튜플에서 3을 추출해서 반환*\n",
    "\n",
    "\n",
    "- **blocks**: raw 형식의 데이터를 모델에 입력 가능한 형식으로 바꿀 규칙을 결정합니다.\n",
    "  - 두 개 이상을 지정할 수 있습니다. **get_x** 및 **get_y** 의 내용을 모두 수용할 수 있어야 합니다. \n",
    "  - 입력과 출력을 구분하기 위한 목적으로 **n_inp** 라는 인자를 건드릴 수 있습니다.\n",
    "    - *예시 1) 이미지 파일 경로에서, 이미지를 불러오고 tensor로 변환하는 ImageBlock. 상위 폴더명을 원-핫 인코딩된 tensor로 변환하는 CategoryBlock*\n",
    "    - *예시 2-1) 이미지 파일 두 개를 수용하기 위한, 두 개의 ImageBlock. 해당 레이블을 원-핫 인코딩 tensor로 변환하는 CategoryBlock*\n",
    "    - *예시 2-2) 이미지 파일 두 개를 한번에 수용 가능한 TupleBlock. 해당 레이블을 원-핫 인코딩 tensor로 변환하는 CategoryBlock*\n",
    "     \n",
    "\n",
    "- **item_tfms**: 각 데이터 하나에 대한 변형을 하고 싶다면, 그 변형 규칙을 지정합니다.\n",
    "\n",
    "\n",
    "- **batch_tfms**: 배치 단위의 데이터에 대한 변형을 하고 싶다면, 그 변형 규칙을 지정합니다.\n",
    "  - 배치 단위의 데이터 변형은 배치 단위로 GPU(가용하다면) 에서 수행됩니다.\n",
    "   \n",
    "- **splitter**: 학습/검증 데이터셋을 구분하는 방법을 결정합니다.\n",
    "  - 두 개(학습/검증)를 포함한 튜플 형식을 반환합니다.\n",
    "  - 각각 리스트이며, 리스트에는 인덱스 목록이 들어 있습니다. **get_items** 에서 누구 인덱스를 학습용으로, 누구 인덱스를 검증용으로 둘 것인지를 나열한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = DataBlock(   \n",
    "    get_items=get_tuples,                       # 모든 데이터를 불러 들이는 함수를 지정합니다.\n",
    "        get_x=get_x,                            # 불러와진 데이터에 대해서, 입력을 결정하는 함수를 지정합니다.\n",
    "        get_y=get_y,                            # 불러와진 데이터에 대해서, 출력을 결정하는 함수를 지정합니다.\n",
    "       blocks=(ImageTupleBlock, CategoryBlock), # tuple 형식으로, 두 개 이상도 가능합니다.\n",
    "    item_tfms=Resize(224),                      # 아이템 단위의 변환\n",
    "   batch_tfms=[Normalize.from_stats(*imagenet_stats)],   # 배치 단위의 변환\n",
    "     splitter=splitter                         # 학습/검증 데이터셋을 분리하는 함수를 지정합니다.        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 설명을 Siamese 데이터 블록에 대입해서 설명해 보자면\n",
    "\n",
    "- **siamese.dataloaders(files)**\n",
    "  - files는 단순히 Path 객체로 표현된 이미지 파일 경로의 목록 입니다.\n",
    "\n",
    "\n",
    "- **get_items**: get_tuples\n",
    "  - get_tuples 함수는 입력된 이미지 파일 경로 목록들로부터, 튜플 (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 목록을 만들어 반환합니다. \n",
    "    - 우선 각 파일을 순차적으로 접근합니다. 접근될 때마다 무작위로 다른 파일을 하나 접근합니다.\n",
    "    - 그리고 두 파일의 카테고리를 추출합니다. 두 파일의 카테고리가 일치한다면 True, 아니라면 False를 레이블로서 정합니다.\n",
    "  \n",
    "  \n",
    "- **get_x**: get_x\n",
    "  - get_x 함수는 **get_tuples** 가 반환한 목록을 하나씩 접근합니다.\n",
    "    - 즉, (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 튜플을 하나씩 처리합니다.\n",
    "    - 해당 튜플 중 처음 두 개만이 입력 데이터이므로 튜플[:2] 를 반환합니다.\n",
    "  \n",
    "  \n",
    "- **get_y**: get_y\n",
    "  - get_y 함수는 **get_tuples** 가 반환한 목록을 하나씩 접근합니다.\n",
    "    - 즉, (이미지 파일 경로 1, 이미지 파일 경로 2, 레이블) 튜플을 하나씩 처리합니다.\n",
    "    - 해당 튜플 중 마지막 하나만이 출력 데이터이므로 튜플[2]를 반환합니다.\n",
    "\n",
    "\n",
    "- **blocks**: (ImageTupleBlock, CategoryBlock)\n",
    "  - ImageTupleBlock은 내부적으로 두 개의 이미지를 입력받고, 이들을 PILImage 형식으로 변환 후 TensorImage 형식으로 변환합니다.\n",
    "    - ImageTupleBlock은 TransformBlock을 반환하는데, TransformBlock에는 type_tfms 및 batch_tfms 인자가 있습니다. type_tfms는 DataBlock의 item_tfms와 동일한 것으로 실제로는 머지되어 처리됩니다. 마찬가지로 TransformBlock에서 지정된 batch_tfms도 DataBlock의 batch_tfms와 머지되어 처리됩니다.\n",
    "      - type_tfms에서 PILImage로의 변환 작업이 지정되고, batch_tfms에서 TensorImage로의 변환 작업이 지정되었습니다.\n",
    "  - CategoryBlock은 주어진 레이블을 원-핫 인코딩된 tensor로 변환합니다.\n",
    "\n",
    "\n",
    "- **item_tfms**: Resize(224)\n",
    "   - 이미지 크기 조절은 Resize 라는 Transform 형 객체를 활용합니다.\n",
    "   - item_tfms에 나열되는 Transform 류는 준비된 데이터 튜플(이미지 파일 경로 1, 이미지 파일 경로 2, 레이블)에 모두 적용됩니다.\n",
    "     - 하지만, 내부적으로 자신이 적용 가능한 녀석이 아니면 그대로 종료됩니다. 즉, 이미지 파일 경로 1, 이미지 파일 경로 2에 대한 변환만이 수행됩니다.\n",
    "\n",
    "\n",
    "\n",
    "- **batch_tfms**: [Normalize.from_stats(*imagenet_stats)]\n",
    "   - **item_tfms** 때와 마찬가지로 적용될 대상을 스스로 알아챕니다\n",
    "   - `Normalize.from_stats(*imagenet_stats)`는 이미지넷 학습에 사용된 데이터의 평균, 표준편차 값으로 전이학습 되는 데이터의 정규화를 수행한다는 의미를 가집니다. 그렇게 해서 전이학습 대상 모델이 학습한 데이터와 유사한 값들로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
