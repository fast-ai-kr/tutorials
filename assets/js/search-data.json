{
  
    
        "post0": {
            "title": "디즈니 캐릭터 분류 모델",
            "content": "fastai(v2) &#46972;&#51060;&#48652;&#47084;&#47532; &#49444;&#52824; . 아래 두 줄의 명령어의 실행이 완료된 다음, 반드시 런타임을 재시작 해야함 . 방법: 런타임 메뉴(Runtime) =&gt; 런타임 재시작 클릭(Restart runtime) | . !git clone https://github.com/fastai/fastai !pip install -e &quot;fastai[dev]&quot; . fastai &#48260;&#51204;&#54869;&#51064; . 대부분의 Python 패키지는 __version__ 속성을 가지고 있는데, 이 속성에 접근하면 현재 설치된 패키지의 버전 정보를 확인할 수 있음. . 아래 코드의 실행 결과가 2.x.x 가 아니라, 1.x.x 라면, fastai v2의 설치가 정상적으로 되지 않은것임. 따라서, 이전 과정을 다시한번 수행/검토해볼 필요가 있음. . import fastai fastai.__version__ . 2.0.7 . fastbook &#51228;&#44277;, &#50976;&#54008;&#47532;&#54000; &#46972;&#51060;&#48652;&#47084;&#47532; &#49444;&#52824; . 마이크로소프트 Bing 검색엔진을 통한 이미지 검색 등의 라이브러리는 fastai 차원에서 제공하는 일반화된 라이브러리가 아님. 다만, 책 내용의 실습을 위해서 fastbook 저장소에서 별도로 작성되어 제공되는것임. . 만약, 책 실습 외의 상황에서도 search_images_bing 등의 API를 사용하고 싶다면, 반드시 아래 코드를 실행하여 fastbook 패키지를 import 해 줘야함. . fastbook의 유틸리티 함수로서 작성된 함수의 목록은 다음과 같음. . search_images_bing | plot_function | draw_tree | cluster_columns | . 딱히 구현상 어려운 수준의 함수는 아니므로, 참고하여 직접 구현해도 됨. . !pip install -Uqq fastbook import fastbook . &#54596;&#50836;&#54620; &#47784;&#46304; &#46972;&#51060;&#48652;&#47084;&#47532;&#47484; import . from fastbook import * from fastai.vision.all import * from fastai.vision.widgets import * . Bing &#51004;&#47196;&#48512;&#53552; &#51060;&#48120;&#51648; &#45796;&#50868;&#47196;&#46300; &#48143; &#45936;&#51060;&#53552;&#49483; &#44396;&#52629; . Azure Cognitive Service API &#53412; &#44050; . API 키를 얻어오기 위해서는 . 일단 MS Azure에 가입이 되어 있어야함 . 계정이 없다면 가입 링크에 접속한 후, &quot;체험 계정 만들기&quot; 버튼을 클릭해서 계정을 생성해야함 | 계정이 있다면, 단순히 로그인만 해 주면 됨 | . | MS Azure 계정이 있다면, 로그인 후 Azure Portal에 접속해 줘야함 . 상단의 검색 바에서 &quot;Cognitive Services&quot;를 타이핑한 다음, 검색된 결과를 클릭함 (당연히 Cognitive Services 라는걸 클릭 해야함) | +New 버튼을 클릭 | Marketplace에서, &quot;Bing Search&quot;를 검색하여 클릭 | &quot;Create&quot; 버튼을 클릭 | 각종 정보 입력. 단, &quot;Pricing Tier&quot;에는 반드시 &quot;무료인 것을 선택&quot; Resource Group이 없는 경우, 텍스트박스 하단의 &quot;New Group&quot;을 클릭하여 하나 생성 | . | . | 생성된 Bing Search 를 클릭 . 좌측 메뉴의 &quot;Keys and Endpoint&quot;를 선택 | &quot;Show Keys&quot; 버튼을 클릭하여, 숨김표시된 Key 값을 풀어줌 | Key1 을 복사하여, 아래의 key 값에 넣어줌 | . | key = &#39;당신만의 Azure Cognitive Service (Bing Search) API Key를 넣어주세요&#39; . &#51060;&#48120;&#51648; &#45796;&#50868;&#47196;&#46300; . 몇 가지 알아두면 좋을만한 정보의 나열 . Path는 fastai에서 개발한 fastcore에 포함된 기초 라이브러리로, 기본적으로는 Python에서 표준적으로 제공하는 pathlib.Path를 확장한 것임. . pathlib.Path의 기능을 모두 그대로 사용 가능하지만, 여기에 다음의 몇 가지 편의 사항을 추가함. .readlines() | .read() | .write() | .save() | .load() | .ls() | . | . | search_images_bing 함수를 이용하여, URL 목록을 가져옴. . Azure Cognitive Service API Key 및 검색하고자 하는 키워드를 파라미터로서 제공 해 줘야함. | 이 함수가 반환하는 객체는 Python의 표준 객체인 list를 확장한 L 이라는 객체임 (fastcore) | . | download_images 함수를 이용하여, 준비된 URL 목록의 모든 이미지를 다운로드함. . 정확히는 results가 URL 목록은 아니며, Bing Search Service가 반환한 JSON 포맷의 내용임. | L 객체는 attrgot 이라는 메서드를 제공하는데, 리스트에 포함된 모든 아이템으로부터 인자로 지정된 속성의 값들만을 추출하여, 별도의 리스트(L)을 반환함. | 첫 번째 인자인 dest가 이미지 다운로드 후 저장될 위치임 | . | . # 아래 한줄의 코드는 일종의 리스트를 만들어줌 (정확히는 Tuple) disney_characters = &#39;disney malificent&#39;, &#39;disney cinderella&#39;, &#39;disney jasmin&#39;, &#39;disney mulan&#39;, &#39;disney belle&#39;, &#39;disney pocahontas&#39; path = Path(&#39;disney&#39;) # 최상위 디렉토리의 생성 if not path.exists(): path.mkdir() # 각 이미지 클래스 별로 반복하여 접근 for character in disney_characters: # 클래스 이름의 Path 지정 및 생성 dest = (path/character) dest.mkdir(exist_ok=True) # search_images_bing 함수를 이용하여, URL 목록을 가져옴 results = search_images_bing(key, character) # download_images 함수를 이용하여, 준비된 URL 목록의 모든 이미지를 다운로드함 download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . &#47784;&#46304; &#51060;&#48120;&#51648;&#54028;&#51068;&#51032; Path &#47785;&#47197; . fastai에서 제공하는 get_image_files는 지정된 Path를 기점으로, 하위에 포함된 모든 이미지 목록을 재귀적으로 검색하여 들고옴 . 구분없이 몽땅 들고오는 이유는 다음과 같음 . 다운로드된 이미지는 폴더이름 단위로 클래스가 구분됨 이후 DataBlock 또는 ImageDataLoaders 객체 생성시 클래스(레이블)을 구분해내기 위한 로직 추가가 가능함. 구분하는 별도의 함수를 만들게 되며, 단순히 규칙을 지정해 주기만 하면됨. | . | . 아래 코드의 실행결과는 fnames 객체 내용을 출력해줌 . 출력 결과의 앞 부분 (#...)은 리스트에 포함된 아이템의 개수를 의미함. 원래 표준 list 객체는 이러한 정보를 출력하지 않으나, L은 출력해 주는 특성이 있음. | . fnames = get_image_files(path) fnames . (#899) [Path(&#39;disney/disney mulan/00000005.jpg&#39;),Path(&#39;disney/disney mulan/00000040.jpg&#39;),Path(&#39;disney/disney mulan/00000122.jpg&#39;),Path(&#39;disney/disney mulan/00000104.png&#39;),Path(&#39;disney/disney mulan/00000068.jpg&#39;),Path(&#39;disney/disney mulan/00000031.jpeg&#39;),Path(&#39;disney/disney mulan/00000058.jpg&#39;),Path(&#39;disney/disney mulan/00000071.jpg&#39;),Path(&#39;disney/disney mulan/00000138.jpg&#39;),Path(&#39;disney/disney mulan/00000091.jpg&#39;)...] . &#47581;&#44032;&#51652; &#47553;&#53356;&#51032; &#51060;&#48120;&#51648; &#44160;&#49324;&#54616;&#50668;, &#44536; &#47785;&#47197;&#51012; &#49325;&#51228;&#54616;&#44592; . failed = verify_images(fnames) failed . (#9) [Path(&#39;disney/disney mulan/00000032.jpg&#39;),Path(&#39;disney/disney belle/00000128.jpg&#39;),Path(&#39;disney/disney belle/00000037.jpg&#39;),Path(&#39;disney/disney jasmin/00000123.jpg&#39;),Path(&#39;disney/disney jasmin/00000011.png&#39;),Path(&#39;disney/disney pocahontas/00000087.jpg&#39;),Path(&#39;disney/disney pocahontas/00000019.jpg&#39;),Path(&#39;disney/disney malificent/00000098.jpeg&#39;),Path(&#39;disney/disney malificent/00000073.jpg&#39;)] . L 객체에는 함수형 언어적 기능인 map 메서드가 구현되어 있음. map 메서드의 파라미터는 어떤 함수가 지정될 수 있음. . map 메서드가 호출되는 순간, 각 아이템을 반복적으로 접근하면서, 제공된 함수를 각 아이템에 적용하여 반환된 결과를 싸그리 모아서 새로운 L 객체를 만들어줌. . Path.unlink 라는 함수가 하는일은 failed 에 포함된 모든 아이템 (Path)에 대하여, 파일을 삭제하는일을 수행함. Path.unlink는 Python의 표준 라이브러리임. . failed.map(Path.unlink) . DataBlock&#51032; &#49373;&#49457; . DataBlock은 DataLoaders를 만들기 위한 저수준의 API. 각 인자가 가지는 의미는 . blocks: Block의 리스트. Block은 데이터를 표현하는 수단 두 개 이상의, 여러개의 Block을 지정하는것도 가능함. 단, 이때는 n_inp 라는 파라미터의 값을 조절하여, 입력으로 사용될 Block이 몇 개인지를 지정해 줘야만 함. 예를 들어서 blocks=(ImageBlock, BBoxBlock, BBoxLblBlock) 처럼 설정했는데 그 중 첫번째만을 입력으로 삼고 싶다면, n_inp=1 이라고 지정해 줘야하만함. | . | get_items: 데이터를 가져오기 위한 함수를 지정 DataBlock 생성 후, DataLoaders를 반환받기 위해서, dataloaders()라는 메서드를 사용하게 됨. dataloaders() 메서드에는 경로(Path)를 지정해 주게 되어 있는데, 이 경로를 기반으로 get_items의 행동이 결정됨. | 가령 아래처럼 get_image_files를 지정하면, dataloaders(path) 메서드 호출시, path 밑에 딸린 모든 이미지를 긁어오게됨 | . | splitter: 데이터를 학습/검증으로 분리해내기 위한 수단을 지정 다양한 Splitter 클래스가 존재함 RandomSplitter | TrainTestSplitter | IndexSplitter | GrandparentSplitter | FuncSplitter | MaskSplitter | FileSplitter | ColSplitter | RandomSubsetSplitter | . | 경우에 따라서, 데이터셋이 미리 train/valid 와 같은 디렉토리로 나뉘어져 제공되는 경우가 있음. 이 때는 splitter에 할당되는 객체의 valid_pct값을 지정하지 않으면 됨. 그러면 자동으로 train 및 valid라는 이름의 디렉토리를 대상으로 삼음. 즉, 다른 이름의 디렉토리라면, 이 이름을 train 및 valid 라는 이름으로 맞춰줘야함. | . | . | get_y: 레이블을 지정하는 수단을 지정 blocks의 출력 개수가 여러개 될 수 있듯이, get_y 또한 여러개가 지정될 수 있다. 이 경우는 리스트에 두 개의 함수를 포함시켜주면 됨. | 기본 제공 parent_label은 단순히, 부모 디렉토리명을 레이블로 보겠다는 뜻이된다. | RegexLabeller도 기본제공되는데 regex 기반으로 레이블을 지정할 수 있어서, 매우 강력함. | . | item_tfms: 각 아이템 별 데이터 변형 . 보통 이미지의 경우, Resize를 해줌 | 왜 Resize를 batch_tfms에서 해주지 않는가 하면, 이미지의 크기가 모두 제각각이기 때문임. GPU는 동일한 크기, 동일한 연산을 동시 다발적 (배치 단위)으로 단순히 계산하는데 최적화 되어 있음. 따라서, 모두 제각각인 이미지를 일단 최초에 동일한 크기로 맞추는 작업은 개별적으로 CPU에서 수행될 필요가 있음. | . | batch_tfms: 배치단위의 데이터 변형 . item_tfms에서 모두 동일한 크기로 맞춰지거나, 쨋든 GPU에서 배치단위로 계산되기에 최적화된 데이터 묶음에 대하여, 묶음 형태의 데이터 변형을 가한다. | 여러가지 변형 방법이 기술될 수 있지만, aug_transforms 를 사용하는것이 초반에는 선호됨. 다양한 데이터 증강 기법들이 모두 포함되어 있음. 링크를 확인해 볼것 | . | . | . | . disney_characters = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2.0, size=224)) . dls = disney_characters.dataloaders(path) . dls.show_batch() . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth . . epoch train_loss valid_loss error_rate time . 0 | 2.595319 | 0.974732 | 0.343195 | 00:29 | . epoch train_loss valid_loss error_rate time . 0 | 1.281569 | 0.564789 | 0.224852 | 00:28 | . 1 | 1.021536 | 0.332185 | 0.118343 | 00:28 | . 2 | 0.805896 | 0.215167 | 0.065089 | 00:29 | . 3 | 0.666769 | 0.199968 | 0.065089 | 00:29 | . learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 0.381612 | 0.194724 | 0.076923 | 00:28 | . epoch train_loss valid_loss error_rate time . 0 | 0.319504 | 0.154517 | 0.059172 | 00:28 | . 1 | 0.319426 | 0.114375 | 0.035503 | 00:29 | . 2 | 0.276944 | 0.107262 | 0.023669 | 00:28 | . 3 | 0.250968 | 0.114793 | 0.035503 | 00:28 | . cleaner = ImageClassifierCleaner(learn) cleaner . count = 0 for idx in cleaner.delete(): cleaner.fns[idx].unlink() count = count+1 print(count) . 4 . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . learn.export() . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . learn_inf = load_learner(&#39;export.pkl&#39;) . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(256,256)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your disney character!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://fast-ai-kr.github.io/tutorials/2020/09/02/disney-character-classifier.html",
            "relUrl": "/2020/09/02/disney-character-classifier.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Tutorial from fastai doc",
            "content": "!git clone --recurse-submodules https://github.com/fastai/fastai !pip install -e &quot;fastai[dev]&quot; . kernel should be re-started after installing fastai-v2 . check fastai-v2 version . import fastai print(fastai.__version__) . 2.0.2 . vision - beginner (dog or cat) . from fastai.vision.all import * . grasp dataset &amp; inspect a bit . path = untar_data(URLs.PETS) print(path.ls()) . (#2) [Path(&#39;/home/user/.fastai/data/oxford-iiit-pet/images&#39;),Path(&#39;/home/user/.fastai/data/oxford-iiit-pet/annotations&#39;)] . # get_image_files # - def get_image_files(path, recurse=True, folders=None): # - Get image files in `path` recursively, only in `folders`, if specified. files = get_image_files(path/&quot;images&quot;) print(len(files)) . 7390 . # just see filename examples for Cat and dog. # - Cat - first capital letter # - dog - all lowercase files[0],files[100] . (Path(&#39;/home/user/.fastai/data/oxford-iiit-pet/images/german_shorthaired_49.jpg&#39;), Path(&#39;/home/user/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_156.jpg&#39;)) . define a label function . all about how to label an item . # takes filename # return how to label it # - if filename is in uppercase =&gt; it&#39;s a Cat =&gt; it is labeled as True # - if filename is in lowercase =&gt; it&#39;s a dog =&gt; it is labeled as False def label_func(filename): return filename[0].isupper() . ImageDataLoaders with from_name_func . from forum about &#39;Why does ImageDataBunch.from_name_re() require a path argument?&#39; . After reading the source code, my current understanding is that path is a required property of the DataBunch parent class, since methods like DataBunch.save() will save directly to path. Additionally, the Learner class usually copies Learner.path from its data.path. This is used for things like Learner.save(), Learner.load(), and Learner.export(), which write to self.path/self.model_dir or just self.path. . # ImageDatLoader&quot;s&quot; # - why plurals? =&gt; multiple DataLoaders (from PyTorch) are in it # - Training/Validation/Testing DataLoader # from_name_func # - path? =&gt; root path of dataset # - fnames? =&gt; list of filenames (image filenames) # - label_func? =&gt; how to label each data? # - item_tfms? =&gt; item transforms dls = ImageDataLoaders.from_name_func(path=path, fnames=files, label_func=label_func, item_tfms=Resize(224)) . dls.show_batch(max_n=12) . cnn_learner with fine_tune . learn = cnn_learner(dls, resnet34, metrics=error_rate) . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /home/user/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth . . # fine_tune is not a simple method # - but all the details are hidden, but also you can adjust the details &quot;&quot;&quot; - Learner.fine_tune(epochs, base_lr=0.002, freeze_epochs=1, lr_mult=100, pct_start=0.3, div=5.0, lr_max=None, div_final=100000.0, wd=None, moms=None, cbs=None, reset_opt=False) &quot;&quot;&quot; learn.fine_tune(epochs=1) . epoch train_loss valid_loss error_rate time . 0 | 0.138832 | 0.016947 | 0.006766 | 00:16 | . epoch train_loss valid_loss error_rate time . 0 | 0.072697 | 0.023958 | 0.008796 | 00:15 | . predict . # results # - first item? =&gt; &quot;predicted label&quot; # - second item? =&gt; index or predicted result tensor # - third item? =&gt; actual output tensor learn.predict(files[0]) . (&#39;False&#39;, tensor(0), tensor([1.0000e+00, 8.6281e-07])) . # just show some randomly chosen data from validation set # - but we can actually choose the target dataset # - with ds_idx argument # - ds_idx=1 is default (validation), 0 is for training set learn.show_results(max_n=12) . # on training dataset learn.show_results(ds_idx=0, max_n=12) . fastai Interpreter . interp = Interpretation.from_learner(learn) . interp.top_losses(k=20) . torch.return_types.topk( values=tensor([5.8659, 4.7590, 4.5521, 1.8459, 1.6657, 1.6071, 1.6005, 1.4597, 1.4470, 1.4424, 1.1674, 1.0468, 0.9538, 0.5710, 0.4560, 0.4243, 0.4099, 0.3973, 0.3943, 0.3182]), indices=tensor([ 873, 1236, 961, 947, 1287, 912, 298, 1154, 662, 307, 361, 1156, 1041, 227, 878, 1308, 94, 1433, 859, 187])) . interp.plot_top_losses(k=20) . classification_interp = ClassificationInterpretation.from_learner(learn) . classification_interp.print_classification_report() . precision recall f1-score support False 0.99 1.00 0.99 1020 True 0.99 0.98 0.99 458 accuracy 0.99 1478 macro avg 0.99 0.99 0.99 1478 weighted avg 0.99 0.99 0.99 1478 . classification_interp.most_confused() . [(True, False, 8), (False, True, 5)] . classification_interp.plot_confusion_matrix() . Using W&amp;B (Weights &amp; Bias) . # install wandb !pip install wandb . # login import wandb wandb.login() . # initialize wandb project # - it will create the project with endpoint wandb.init(project=&#39;my_project&#39;) . # import wandb callback in fastai from fastai.callback.wandb import * # leave logs for everything learn = cnn_learner(dls, resnet34, metrics=error_rate, cbs=WandbCallback()) learn.fine_tune(epochs=4) # leave logs for training process only # - learn.fine_tune(epochs=4, cbs=WandbCallback()) . vision - beginner (dog breed) . from fastai.vision.all import * path = untar_data(URLs.PETS) files = get_image_files(path/&quot;images&quot;) . pat = r&#39;^(.*)_ d+.jpg&#39; . dls = ImageDataLoaders.from_name_re(path=path, fnames=files, pat=pat, item_tfms=Resize(224)) dls.show_batch() . dls = ImageDataLoaders.from_name_re(path=path, fnames=files, pat=pat, item_tfms=Resize(460), batch_tfms=aug_transforms(size=224)) . dls.show_batch() . learn = cnn_learner(dls, resnet34, metrics=error_rate) . learn.lr_find() . SuggestedLRs(lr_min=0.010000000149011612, lr_steep=0.005248074419796467) . learn.fine_tune(4, 5e-3) . epoch train_loss valid_loss error_rate time . 0 | 1.116782 | 0.310870 | 0.099459 | 00:21 | . epoch train_loss valid_loss error_rate time . 0 | 0.520518 | 0.547198 | 0.158999 | 00:21 | . 1 | 0.541868 | 0.341918 | 0.100812 | 00:21 | . 2 | 0.318754 | 0.291615 | 0.081867 | 00:21 | . 3 | 0.162863 | 0.236776 | 0.070365 | 00:21 | . learn.show_results() . interp = Interpretation.from_learner(learn) interp.plot_top_losses(9, figsize=(15,10)) . classification_interp = ClassificationInterpretation.from_learner(learn) classification_interp.print_classification_report() . precision recall f1-score support Abyssinian 0.93 0.91 0.92 45 Bengal 0.85 0.85 0.85 39 Birman 0.90 0.97 0.94 38 Bombay 0.97 1.00 0.98 32 British_Shorthair 0.91 0.98 0.94 41 Egyptian_Mau 0.88 0.90 0.89 42 Maine_Coon 0.92 0.92 0.92 52 Persian 1.00 0.89 0.94 36 Ragdoll 0.86 0.88 0.87 43 Russian_Blue 0.97 0.90 0.94 40 Siamese 0.93 0.93 0.93 40 Sphynx 0.98 0.93 0.96 46 american_bulldog 0.84 0.79 0.81 33 american_pit_bull_terrier 0.73 0.75 0.74 40 basset_hound 1.00 0.97 0.99 35 beagle 0.86 0.95 0.90 40 boxer 0.85 0.90 0.88 39 chihuahua 0.80 0.93 0.86 30 english_cocker_spaniel 0.91 1.00 0.95 39 english_setter 0.97 0.91 0.94 34 german_shorthaired 0.94 1.00 0.97 34 great_pyrenees 0.98 0.98 0.98 52 havanese 0.89 0.98 0.93 42 japanese_chin 1.00 1.00 1.00 47 keeshond 1.00 0.97 0.99 36 leonberger 0.97 1.00 0.99 36 miniature_pinscher 0.89 0.89 0.89 45 newfoundland 1.00 1.00 1.00 40 pomeranian 1.00 0.97 0.99 40 pug 1.00 0.95 0.97 37 saint_bernard 0.90 0.96 0.93 28 samoyed 1.00 0.97 0.99 40 scottish_terrier 0.98 0.98 0.98 46 shiba_inu 1.00 0.94 0.97 33 staffordshire_bull_terrier 0.86 0.79 0.82 61 wheaten_terrier 1.00 0.95 0.97 39 yorkshire_terrier 1.00 0.87 0.93 38 accuracy 0.93 1478 macro avg 0.93 0.93 0.93 1478 weighted avg 0.93 0.93 0.93 1478 . classification_interp.most_confused(min_val=3) . [(&#39;staffordshire_bull_terrier&#39;, &#39;american_pit_bull_terrier&#39;, 5), (&#39;Bengal&#39;, &#39;Egyptian_Mau&#39;, 4), (&#39;Egyptian_Mau&#39;, &#39;Bengal&#39;, 4), (&#39;Maine_Coon&#39;, &#39;Ragdoll&#39;, 4), (&#39;american_pit_bull_terrier&#39;, &#39;staffordshire_bull_terrier&#39;, 4), (&#39;Russian_Blue&#39;, &#39;British_Shorthair&#39;, 3), (&#39;Sphynx&#39;, &#39;chihuahua&#39;, 3), (&#39;american_bulldog&#39;, &#39;american_pit_bull_terrier&#39;, 3), (&#39;american_pit_bull_terrier&#39;, &#39;miniature_pinscher&#39;, 3), (&#39;staffordshire_bull_terrier&#39;, &#39;american_bulldog&#39;, 3), (&#39;yorkshire_terrier&#39;, &#39;havanese&#39;, 3)] . classification_interp.plot_confusion_matrix(figsize=(20,15)) .",
            "url": "https://fast-ai-kr.github.io/tutorials/2020/08/03/image-classification.html",
            "relUrl": "/2020/08/03/image-classification.html",
            "date": " • Aug 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://fast-ai-kr.github.io/tutorials/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://fast-ai-kr.github.io/tutorials/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}